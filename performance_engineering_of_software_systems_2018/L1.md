## Lecture 1 - Introduction and Matrix Multiplication

What software properties are more important than performance?

Performance is the currency of computing. 

Software performance engineering was common, because machine resources were limited.

"Premature optimization is the root of all evil."
"The First Rule of Program Optimization: Don't do it. The Second Rule: For experts only - don't do it yet."

#### The art: make code readable and fast!

Performance was gained from Moores Law and Scalling Clock Speeds. Hardware could mitigate the slow software.

Performance is no longer free:
Generally, software needs to adapt to utilize all hardware advancements (multicore, caches, etc.)

### Theoretical calculation for the Matrix Multiplication example

2n^3 = 2^37 floating-point operations
Running time = 21042 secons
Python gets: 2^37 / 21042 = 6.25 MFLOPS
Peak: 836 GFLOPS (of machine)
Python gets: 0.00075% of peak

Java: 2738 s
About 8.8x faster than Python

C: 1156 s
About: 2x faster than Java

### JIT compilation

* When code is first executed, it is interpreted.
* The runtime system keeps track of how often the various pieces of
code are executed.
* Whenever some piece of code executes sufficiently frequently,
it gets compiled to machine code in real time.
* Future executions of that code use the more-efficient compiled
version.


### Performance from different loop order
Hardware Caches - maximize cache hits, while minimizing misses.

### Measure the effects of different access patterns
`valgrind --tool=cachegrind ./mm`

### Compiler Optimizations
Check what times are using different compiler flags (-Ox where x 0 - 3)

### Parallel Loops with `cilk_for`

Rule of thumb: parallelize outer loops rather than inner loops.

### Data reuse (maximize spacial locality = more cache hits)
* loops
* blocks (tilling) - same result (coverage) in C, but muss less accesses
* divide and conquer

### Vector Hardware
SIMD - single instruction multiple data
Compiler vectorization - Clang/LLVM uses vector instructions automaticaly when compiling at -O2
or higher. It can be induced to produce a vectorization report as follows:
`clang -O3 -std=c00 mm.c -o mm -Rpass=vector`

Vectorization flags:
* -mavx: use intel AVX
* -mavx2: use intel AVX2
* -mfma: use fused multiply-add
* -march=<string>: use whatever instructions are available for specified arch.
* -march=native: use whatever instructions are available on the arch of compilation.

Due to restrictions on floating-point arithmetic, additional flags, such as -ffast-math might
be needed for these vectorization flags to have an effect.

Its not associative (a * b * c != c **** b * a)

+ Intel AVX instructions instristic




